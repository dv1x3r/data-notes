{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils as skutils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _LogisticRegression:\n",
    "    \n",
    "    def __init__(self, init='mini-batch', alpha=0.0001, epsilon=0.1, max_iter=300):\n",
    "        self.init = init\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.iter = None\n",
    "        \n",
    "    def fit(self, X, y, batch_size=None):\n",
    "        X = np.array(X)\n",
    "        y = y.reshape(-1, 1)\n",
    "        self.intercept_ = np.random.normal(loc=0, scale=0.01)\n",
    "        self.coef_ = np.random.normal(loc=0, scale=0.01, size=(len(X.T), 1))\n",
    "        self.iter = 0\n",
    "\n",
    "        if self.init == 'mini-batch':\n",
    "            self._mini_batch(X, y, batch_size)\n",
    "        else:\n",
    "            self._batch(X, y)\n",
    "  \n",
    "        return self\n",
    "    \n",
    "    def _create_batches(self, X, y, batch_size):\n",
    "        Xb, yb = skutils.shuffle(X, y)\n",
    "        batches = (int)(len(X) / (batch_size or len(X)))\n",
    "        Xb = np.array_split(Xb, batches)\n",
    "        yb = np.array_split(yb, batches)\n",
    "        return zip(Xb, yb)\n",
    "    \n",
    "    def _mini_batch(self, X, y, batch_size):\n",
    "        while True:\n",
    "            self.iter += 1\n",
    "            if self.iter > self.max_iter:\n",
    "                break\n",
    "                \n",
    "            old_cost = self._cost(X, y)\n",
    "    \n",
    "            for X, y in self._create_batches(X, y, batch_size):\n",
    "                e = np.ones(len(X))\n",
    "                z = self._z(X)\n",
    "                y_cap = self._sigmoid(z)\n",
    "            \n",
    "                delta_b = -self.alpha * -e.dot(y - y_cap)\n",
    "                delta_w = -self.alpha * -X.T.dot(y - y_cap)\n",
    "                self.intercept_ += delta_b\n",
    "                self.coef_ += delta_w\n",
    "    \n",
    "            new_cost = self._cost(X, y)\n",
    "            if abs(new_cost - old_cost) < self.epsilon:\n",
    "                break\n",
    "    \n",
    "    def _batch(self, X, y):\n",
    "        while True:\n",
    "            self.iter += 1\n",
    "            if self.iter > self.max_iter:\n",
    "                break\n",
    "\n",
    "            e = np.ones(len(X))\n",
    "            z = self._z(X)\n",
    "            y_cap = self._sigmoid(z)\n",
    "            \n",
    "            delta_b = -self.alpha * -e.dot(y - y_cap)\n",
    "            delta_w = -self.alpha * -X.T.dot(y - y_cap)\n",
    "            self.intercept_ += delta_b\n",
    "            self.coef_ += delta_w\n",
    "            \n",
    "            if (delta_b ** 2) + (delta_w ** 2).sum() < self.epsilon:\n",
    "                break\n",
    "    \n",
    "    def _cost(self, X, y):\n",
    "        z = self._z(X)\n",
    "        y_cap = self._sigmoid(z)\n",
    "        return (y * np.log(y_cap) + (1 - y) * np.log(1 - y_cap)).sum()\n",
    "    \n",
    "    # weighted input function\n",
    "    def _z(self, X):\n",
    "        return X.dot(self.coef_) + self.intercept_\n",
    "        \n",
    "    # logistic function\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # quantizer\n",
    "    def _q(self, a):\n",
    "        return np.where(a < 0.5, 0, 1).reshape(1, -1)[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = self._z(X)\n",
    "        y_cap = self._sigmoid(z) \n",
    "        return self._q(y_cap)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'sex', 'cp', 'trestbps','chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat', delimiter=' ', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_attributes = [0,3,4,7,9,11]\n",
    "ordered_attributes = [10]\n",
    "binary_attributes = [1,5,8]\n",
    "nominal_attributes = [6,2,12]\n",
    "target_attribute = 'num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_attribute] = np.where(df[target_attribute] == 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,real_attributes] = StandardScaler().fit_transform(df.iloc[:,real_attributes])\n",
    "df.iloc[:,ordered_attributes] = Normalizer().fit_transform(df.iloc[:,ordered_attributes])\n",
    "df = pd.get_dummies(df, columns=df.columns[nominal_attributes], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fields = list(df.drop(target_attribute, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.712094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.075410</td>\n",
       "      <td>1.402212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.759208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.181012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.472682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.382140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.916759</td>\n",
       "      <td>6.093004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.711535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.411950</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.375291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.656118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.711535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.052186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.187590</td>\n",
       "      <td>0.258589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.932198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.743600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.152032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.636310</td>\n",
       "      <td>0.374890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.240239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.743600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex  trestbps      chol  fbs   thalach  exang   oldpeak  slope  \\\n",
       "0  1.712094  1.0 -0.075410  1.402212  0.0 -1.759208    0.0  1.181012    1.0   \n",
       "1  1.382140  0.0 -0.916759  6.093004  0.0  0.446409    0.0  0.481153    1.0   \n",
       "2  0.282294  1.0 -0.411950  0.219823  0.0 -0.375291    0.0 -0.656118    1.0   \n",
       "3  1.052186  1.0 -0.187590  0.258589  0.0 -1.932198    1.0 -0.743600    1.0   \n",
       "4  2.152032  0.0 -0.636310  0.374890  0.0 -1.240239    1.0 -0.743600    1.0   \n",
       "\n",
       "         ca  num  restecg_1.0  restecg_2.0  cp_2.0  cp_3.0  cp_4.0  thal_6.0  \\\n",
       "0  2.472682    1            0            1       0       0       1         0   \n",
       "1 -0.711535    0            0            1       0       1       0         0   \n",
       "2 -0.711535    1            0            0       1       0       0         0   \n",
       "3  0.349871    0            0            0       0       0       1         0   \n",
       "4  0.349871    0            0            1       1       0       0         0   \n",
       "\n",
       "   thal_7.0  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[all_fields], np.array(df[target_attribute]), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _LogisticRegression(init='batch', alpha=0.01, epsilon=0.001).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations 29\n",
      "train set accuracy 0.8842592592592593\n",
      "test set accuracy 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print('total iterations', model.iter)\n",
    "print('train set accuracy', model.score(X_train, y_train))\n",
    "print('test set accuracy', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _LogisticRegression(init='mini-batch', alpha=0.01).fit(X_train, y_train, batch_size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations 22\n",
      "train set accuracy 0.7824074074074074\n",
      "test set accuracy 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "print('total iterations', model.iter)\n",
    "print('train set accuracy', model.score(X_train, y_train))\n",
    "print('test set accuracy', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _LogisticRegression(init='mini-batch', alpha=0.01).fit(X_train, y_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations 2\n",
      "train set accuracy 0.7916666666666666\n",
      "test set accuracy 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "print('total iterations', model.iter)\n",
    "print('train set accuracy', model.score(X_train, y_train))\n",
    "print('test set accuracy', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
