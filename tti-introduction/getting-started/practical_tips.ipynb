{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style guide & practical tips on Machine Learning Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sctucture your project\n",
    "- Use *Jupyter* cells in one-per-action fashion: one - for imports, one - for reading data, one - for displaying a plot etc.  \n",
    "- Use *Markdown* syntax to add headings and comments (switch cell type to *Markdown*).\n",
    "- Don't encapsulate your code into separate *.py* files: our projects are pretty small and may be stored into one *Jupyter* notebook.\n",
    "- Keep cells in logical order: rerunning *Jupyter* document (Kernel > Restart & Run All) shouldn't break your program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Organize imports\n",
    "- Import everything you need in the first cell.\n",
    "- Use conventional aliases for packages: they are generally accepted, so you may even google for something like 'pd remove column'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obey naming convention\n",
    "- Obey uppercase/lowercase rule: vectors and scalars are expected to be stored into lowercase variables, matrices - into uppercase ones.\n",
    "- Use generally accepted naming:  \n",
    "store feature matrix into capital `X`,  \n",
    "target variable - into lowercase `y`,  \n",
    "lowercase `x` is expected to store single observation,  \n",
    "pandas.**DataFrame** should be stored into just `df` if you have single DataFrame in your program, or name it more specifically if needed, e.g. `test_df`  \n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "FILE_NAME = 'iris.data.csv'\n",
    "\n",
    "file_path = os.path.join(DATA_DIR, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:, :-1]\n",
    "y = df.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uppercase/lowercase rule is also related to functions: uppercase parameter means that matrix is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    for x in X:\n",
    "        w = None\n",
    "        b = None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Respect levels of abstraction\n",
    "- *pandas* is a high-level API for *numpy* arrays. So use high level when it is logical (i.e. mostly always):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low level: what are features 0 and 2?\n",
    "X = df.values[:, [0, 2]]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high level: we want to selecl just ['sepal length', 'petal length']\n",
    "X = df[['sepal length', 'petal length']].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The common rule is to use *pandas* for data preprocessing and *numpy* - for training and further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing, use df\n",
    "# ...\n",
    "\n",
    "X = df.values[:, :-1]\n",
    "y = df.values[:, -1]\n",
    "\n",
    "# training, use X and y\n",
    "# ...\n",
    "# performance evaluation\n",
    "# etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respecting levels of abstraction is not only related to *pandas/numpy* but even more to every single line of code.\n",
    "- Define functions even if they won't be reused, just to keep your code at the same level of abstraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high level\n",
    "df = read_data()\n",
    "preprocessed_df = preprocess(df)\n",
    "\n",
    "X = preprocessed_df.values[:, :-1]\n",
    "y = preprocessed_df.values[:, -1]\n",
    "\n",
    "# low level model training\n",
    "# to be replaced with 'fit(X, y)'\n",
    "for x in X:\n",
    "    w = None\n",
    "    b = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Avoid explicit loops\n",
    "- *numpy* gives you encapsulated implementation of matrix operations called *vectorization*. It's much faster and often makes code more clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d(x, x^{'}) = \\sqrt{\\sum_{j = 1}^{m} (x_j - x_j^{'}) ^ {2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(((x1 - x2) ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 4, 3, 5],\n",
    "    [2, 3, 6, 10]\n",
    "])\n",
    "\n",
    "euclidean_distance(X[0], X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that it is not always possible to avoid explicit loops. For example, explicit loops cannot be avoided in the following cases:  \n",
    "\\- iterating over epochs (passes of the entire training set when training your model),  \n",
    "\\- iterating over mini-batches when using mini-batch gradient descent.  \n",
    "However, analyze each case carefully. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Don't use 1-D *numpy* arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avoid using 1-D *numpy* arrays wherever it is possible: matrix operations may return unexpected result. Use  \n",
    "numpy.**reshape**  \n",
    "to convert arrays to 2-D\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-D: (5,)\n",
      "2-D, row: (1, 5)\n",
      "2-D, column: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "x_row = x.reshape(1, -1)\n",
    "x_column = x.reshape(-1, 1)\n",
    "\n",
    "print('1-D:', x.shape)\n",
    "print('2-D, row:', x_row.shape)\n",
    "print('2-D, column:', x_column.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some library functions require 1-D arrays as input. Use numpy.**ravel** to make your arrays 1-D:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_row.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_column.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Follow *scikit-learn* interface when implementing your own models\n",
    "- For example, see sklearn.cluster.**KMeans** docs when developing your own *k-means* implementation\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "This is a well-thought-out style, best practice. However, you also will be able to easily switch between your own and out-of-the-box implementations of Machine Learning models without changing surrounding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKMeans:\n",
    "    def __init__(self, n_clusters, init='random', n_init=1, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X):\n",
    "        pass\n",
    "        self.cluster_centers_ = None\n",
    "\n",
    "    def predict(self, X):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "kmeans = MyKMeans(n_clusters=3, init='k-means++')\n",
    "kmeans.fit(X)\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement every *scikit-learn* offered option for model training if you are familiar with the theory behind it or just think that it's easy and useful thing. We didn't learn `max_iter` option for *k-means* method. But that's easy. So why not to implement it on your own?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Use library code wherever possible\n",
    "- Implementation Machine Learining models on your own for study purposes, however maximize library usage when developing your own implementation and everything around it.\n",
    "- Use *pandas* for high-level data preprocessing.\n",
    "- Use *numpy* and *scipy* for fast and readable code with matrix operations and other calculations.\n",
    "- Use *scikit-learn* for out-of-the-box implementation of general Machine Learning operations: sample split, performance evaluation etc.\n",
    "- Learn best practices by examples. Google for every high-level concept you are going to implement. Need to randomly choose some rows of *numpy* matrix? Google for examples!\n",
    "\n",
    "By the way, did you notice that we used `os.path.join` to concatenate path to our data source? This cross-platform implementation saves our time, handling many cases and making our code more readable. Once again: google for examples of every concept you are going to implement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Do your own research\n",
    "- Proof your decisions with examples and statistics.\n",
    "\n",
    "**Example 1.** You need to choose learning rate $\\alpha$.  \n",
    "Try some options. Measure number of iterations needed for convergence of learning. Track dynamics of model performance while learning (measure cost), you may even plot it. Use metrics (*accuracy* e.g.) to evaluate performance of the trained model on training and validation sets.\n",
    "\n",
    "**Example 2.** You have implemented an improvement: *k-means++* initialization.  \n",
    "Why is it better than random initialization? Make experiments. Train your model for many times. Say, 100. Measure average epoch (passes over the training set) number needed for convergence for both types of initialization. Measure classification performance (*accuracy*, at least). Compare results and voila! Your decision is reasoned!\n",
    "\n",
    "**Example 3.** You have implemented an improvement: *mini-batch gradient descent* for model training.  \n",
    "Why is it better than batch gradient descent? Track learning performance. How many epochs were needed for learning convergence in both cases? What \\[physical\\] time did calculations take? Plot the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
